{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4bb9bd0-50a5-460f-b638-ef19fd09edf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2627429-7eb2-4f3b-a868-73ba4801e212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "detect_data = pd.read_csv('detect_dataset-for-3phase-machine.csv')\n",
    "class_data = pd.read_csv('classData-for-3phase-machine.csv')\n",
    "\n",
    "# Remove empty columns from detect dataset\n",
    "detect_data_cleaned = detect_data.drop(columns=['Unnamed: 7', 'Unnamed: 8'])\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "detect_data_normalized = scaler.fit_transform(detect_data_cleaned)\n",
    "class_data_normalized = scaler.fit_transform(class_data)\n",
    "\n",
    "# Split the detect dataset into features and labels\n",
    "X_detect = detect_data_normalized[:, 1:]  # Features\n",
    "y_detect = detect_data_normalized[:, 0]   # Labels\n",
    "\n",
    "# Split the class dataset into features and labels\n",
    "X_class = class_data_normalized[:, 4:]  # Features\n",
    "y_class = class_data_normalized[:, :4]  # Labels\n",
    "\n",
    "# Further split the data into training and testing sets\n",
    "X_train_detect, X_test_detect, y_train_detect, y_test_detect = train_test_split(X_detect, y_detect, test_size=0.2, random_state=42)\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fbecd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403028</td>\n",
       "      <td>0.508126</td>\n",
       "      <td>0.585337</td>\n",
       "      <td>0.548701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>0.506422</td>\n",
       "      <td>0.560017</td>\n",
       "      <td>0.587308</td>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.932806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448420</td>\n",
       "      <td>0.505107</td>\n",
       "      <td>0.543364</td>\n",
       "      <td>0.619020</td>\n",
       "      <td>0.042432</td>\n",
       "      <td>0.882066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454217</td>\n",
       "      <td>0.504316</td>\n",
       "      <td>0.538410</td>\n",
       "      <td>0.631410</td>\n",
       "      <td>0.044794</td>\n",
       "      <td>0.867087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463271</td>\n",
       "      <td>0.503306</td>\n",
       "      <td>0.530447</td>\n",
       "      <td>0.651058</td>\n",
       "      <td>0.053129</td>\n",
       "      <td>0.838493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461942</td>\n",
       "      <td>0.524456</td>\n",
       "      <td>0.508940</td>\n",
       "      <td>0.581149</td>\n",
       "      <td>0.083788</td>\n",
       "      <td>0.876617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462161</td>\n",
       "      <td>0.523902</td>\n",
       "      <td>0.509278</td>\n",
       "      <td>0.588753</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.871547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462389</td>\n",
       "      <td>0.523347</td>\n",
       "      <td>0.509609</td>\n",
       "      <td>0.596333</td>\n",
       "      <td>0.078980</td>\n",
       "      <td>0.866384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462624</td>\n",
       "      <td>0.522792</td>\n",
       "      <td>0.509933</td>\n",
       "      <td>0.603888</td>\n",
       "      <td>0.076741</td>\n",
       "      <td>0.861131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462868</td>\n",
       "      <td>0.522235</td>\n",
       "      <td>0.510250</td>\n",
       "      <td>0.611417</td>\n",
       "      <td>0.074613</td>\n",
       "      <td>0.855787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12001 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6\n",
       "0      0.0  0.403028  0.508126  0.585337  0.548701  0.000000  0.997697\n",
       "1      0.0  0.430292  0.506422  0.560017  0.587308  0.024312  0.932806\n",
       "2      0.0  0.448420  0.505107  0.543364  0.619020  0.042432  0.882066\n",
       "3      0.0  0.454217  0.504316  0.538410  0.631410  0.044794  0.867087\n",
       "4      0.0  0.463271  0.503306  0.530447  0.651058  0.053129  0.838493\n",
       "...    ...       ...       ...       ...       ...       ...       ...\n",
       "11996  0.0  0.461942  0.524456  0.508940  0.581149  0.083788  0.876617\n",
       "11997  0.0  0.462161  0.523902  0.509278  0.588753  0.081329  0.871547\n",
       "11998  0.0  0.462389  0.523347  0.509609  0.596333  0.078980  0.866384\n",
       "11999  0.0  0.462624  0.522792  0.509933  0.603888  0.076741  0.861131\n",
       "12000  0.0  0.462868  0.522235  0.510250  0.611417  0.074613  0.855787\n",
       "\n",
       "[12001 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(class_data_normalized)\n",
    "pd.DataFrame(detect_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0905e-140a-493a-a40e-0b6070128fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balance_data(X, y):\n",
    "    # Combine the data\n",
    "    data = np.hstack((X, y.reshape(-1, 1)))\n",
    "    # Separate the classes\n",
    "    classes = np.unique(y)\n",
    "    max_size = max(Counter(y).values())\n",
    "    resampled_data = []\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_data = data[data[:, -1] == cls]\n",
    "        resampled_cls_data = resample(cls_data, replace=True, n_samples=max_size, random_state=42)\n",
    "        resampled_data.append(resampled_cls_data)\n",
    "\n",
    "    resampled_data = np.vstack(resampled_data)\n",
    "    np.random.shuffle(resampled_data)\n",
    "\n",
    "    X_resampled = resampled_data[:, :-1]\n",
    "    y_resampled = resampled_data[:, -1]\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Balance the detect dataset\n",
    "X_train_detect_balanced, y_train_detect_balanced = balance_data(X_train_detect, y_train_detect)\n",
    "\n",
    "# Balance the class dataset\n",
    "y_train_class_labels = np.argmax(y_train_class, axis=1)  # Convert one-hot to single label for balancing\n",
    "X_train_class_balanced, y_train_class_balanced_labels = balance_data(X_train_class, y_train_class_labels)\n",
    "y_train_class_balanced = pd.get_dummies(y_train_class_balanced_labels).values  # Convert back to one-hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be9c0f-3e2e-4275-a975-e7fff63535d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ELM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_neurons=1000, activation_function='sigmoid'):\n",
    "        self.n_hidden_neurons = n_hidden_neurons\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def _activation(self, X):\n",
    "        if self.activation_function == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-X))\n",
    "        elif self.activation_function == 'tanh':\n",
    "            return np.tanh(X)\n",
    "        else:\n",
    "            raise ValueError('Unsupported activation function')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights and biases\n",
    "        self.input_weights = np.random.randn(X.shape[1], self.n_hidden_neurons) * 0.01\n",
    "        self.biases = np.random.randn(self.n_hidden_neurons) * 0.01\n",
    "        \n",
    "        # Compute hidden layer output (H)\n",
    "        H = self._activation(np.dot(X, self.input_weights) + self.biases[np.newaxis, :])\n",
    "        \n",
    "        # Compute output weights using the pseudo-inverse of H\n",
    "        self.output_weights = np.dot(np.linalg.pinv(H), y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Compute hidden layer output\n",
    "        H = self._activation(np.dot(X, self.input_weights) + self.biases[np.newaxis, :])\n",
    "        predictions = np.dot(H, self.output_weights)\n",
    "        \n",
    "        # Binary classification: Apply threshold\n",
    "        return (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca9bab-74f2-4e0b-8998-936cfb184281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and train the ELM model for fault detection\n",
    "elm_model_detect = ELM(n_hidden_neurons=500, activation_function='sigmoid')\n",
    "print(elm_model_detect.fit(X_train_detect_balanced, y_train_detect_balanced))\n",
    "\n",
    "# Predict on test data for fault detection\n",
    "y_pred_detect = elm_model_detect.predict(X_test_detect)\n",
    "y_pred_detect = np.round(y_pred_detect)\n",
    "\n",
    "\n",
    "# Iterate through predictions and test data\n",
    "for i, (true_val, pred_val) in enumerate(zip(y_test_detect, y_pred_detect)):\n",
    "    if pred_val == 1:\n",
    "        print(f\"Fault detected in sample {i + 1}: Predicted value = {pred_val}, True value = {true_val}\")\n",
    "    else:\n",
    "        print(f\"No fault detected in sample {i + 1}: Predicted value = {pred_val}, True value = {true_val}\")\n",
    "\n",
    "# Evaluate the model for fault detection\n",
    "accuracy_detect = accuracy_score(y_test_detect, y_pred_detect)\n",
    "precision_detect = precision_score(y_test_detect, y_pred_detect, average='macro')\n",
    "recall_detect = recall_score(y_test_detect, y_pred_detect, average='macro')\n",
    "f1_detect = f1_score(y_test_detect, y_pred_detect, average='macro')\n",
    "conf_matrix_detect = confusion_matrix(y_test_detect, y_pred_detect)\n",
    "\n",
    "# Print evaluation metrics for fault detection\n",
    "print('Fault Detection Evaluation Metrics:')\n",
    "print('Accuracy:', accuracy_detect)\n",
    "print('Precision:', precision_detect)\n",
    "print('Recall:', recall_detect)\n",
    "print('F1 Score:', f1_detect)\n",
    "print('Confusion Matrix:\\n', conf_matrix_detect)\n",
    "print(f\"Confusion Matrix:\\n\")\n",
    "print(f\"True No Fault (0), Predicted No Fault (0): {conf_matrix_detect[0, 0]}\")\n",
    "print(f\"True No Fault (0), Predicted Fault (1): {conf_matrix_detect[0, 1]}\")\n",
    "print(f\"True Fault (1), Predicted No Fault (0): {conf_matrix_detect[1, 0]}\")\n",
    "print(f\"True Fault (1), Predicted Fault (1): {conf_matrix_detect[1, 1]}\")\n",
    "print(f\"Number of actual faults in the test data: {sum(y_test_detect)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1d05b-3f0b-4607-8b82-3d2024f558ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and train the ELM model for fault classification\n",
    "elm_model_class = ELM(n_hidden_neurons=700, activation_function='sigmoid')\n",
    "elm_model_class.fit(X_train_class_balanced, y_train_class_balanced)\n",
    "\n",
    "# Predict on test data for fault classification\n",
    "y_pred_class = elm_model_class.predict(X_test_class)\n",
    "y_pred_class = np.round(y_pred_class)\n",
    "\n",
    "# Evaluate the model for fault classification\n",
    "accuracy_class = accuracy_score(y_test_class.argmax(axis=1), y_pred_class.argmax(axis=1))\n",
    "precision_class = precision_score(y_test_class.argmax(axis=1), y_pred_class.argmax(axis=1), average='macro')\n",
    "recall_class = recall_score(y_test_class.argmax(axis=1), y_pred_class.argmax(axis=1), average='macro')\n",
    "f1_class = f1_score(y_test_class.argmax(axis=1), y_pred_class.argmax(axis=1), average='macro')\n",
    "conf_matrix_class = confusion_matrix(y_test_class.argmax(axis=1), y_pred_class.argmax(axis=1))\n",
    "\n",
    "# Print evaluation metrics for fault classification\n",
    "print('Fault Classification Evaluation Metrics:')\n",
    "print('Accuracy:', accuracy_class)\n",
    "print('Precision:', precision_class)\n",
    "print('Recall:', recall_class)\n",
    "print('F1 Score:', f1_class)\n",
    "print('Confusion Matrix:\\n', conf_matrix_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20625d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot confusion matrix for fault detection\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(conf_matrix_detect, classes=['No Fault', 'Fault'], title='Confusion Matrix for Fault Detection')\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix for fault classification (if it applies)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(conf_matrix_class, classes=['Class 0', 'Class 1'], title='Confusion Matrix for Fault Classification')\n",
    "plt.show()\n",
    "\n",
    "# Create a figure for evaluation metrics for fault detection and classification\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot metrics for fault detection\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Metric', y='Value', data=metrics_detect)\n",
    "plt.title('Evaluation Metrics for Fault Detection')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot metrics for fault classification\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Metric', y='Value', data=metrics_class)\n",
    "plt.title('Evaluation Metrics for Fault Classification')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Function to plot confusion matrix\n",
    "# def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(np.unique(cm)))\n",
    "#     plt.xticks(tick_marks, np.unique(cm), rotation=45)\n",
    "#     plt.yticks(tick_marks, np.unique(cm))\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "\n",
    "# # Plot confusion matrix for fault detection\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plot_confusion_matrix(conf_matrix_detect, title='Confusion Matrix for Fault Detection')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot confusion matrix for fault classification\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plot_confusion_matrix(conf_matrix_class, title='Confusion Matrix for Fault Classification')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot evaluation metrics\n",
    "# metrics_detect = pd.DataFrame({\n",
    "#     'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "#     'Value': [accuracy_detect, precision_detect, recall_detect, f1_detect]\n",
    "# })\n",
    "\n",
    "# metrics_class = pd.DataFrame({\n",
    "#     'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "#     'Value': [accuracy_class, precision_class, recall_class, f1_class]\n",
    "# })\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.barplot(x='Metric', y='Value', data=metrics_detect)\n",
    "# plt.title('Evaluation Metrics for Fault Detection')\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# sns.barplot(x='Metric', y='Value', data=metrics_class)\n",
    "# plt.title('Evaluation Metrics for Fault Classification')\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e394db-aed3-424c-9ca4-01aad6c44834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890c19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
